{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SWE Class\\Github Desktop\\NLP-Learning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.3 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='distilbert-base-uncased')\n",
    "unmasker(\"Life is ratehr [MASK], don't you think? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76568449e-02  6.34959415e-02  4.87130918e-02  7.93049783e-02\n",
      "   3.74479815e-02  2.65283976e-03  3.93749401e-02 -7.09840935e-03\n",
      "   5.93614094e-02  3.15369740e-02  6.00980520e-02 -5.29052168e-02\n",
      "   4.06067818e-02 -2.59308834e-02  2.98428107e-02  1.12694828e-03\n",
      "   7.35149682e-02 -5.03818765e-02 -1.22386634e-01  2.37028915e-02\n",
      "   2.97264755e-02  4.24769036e-02  2.56338175e-02  1.99526479e-03\n",
      "  -5.69191203e-02 -2.71598324e-02 -3.29035297e-02  6.60248995e-02\n",
      "   1.19007096e-01 -4.58791256e-02 -7.26214871e-02 -3.25839706e-02\n",
      "   5.23413792e-02  4.50552851e-02  8.25304259e-03  3.67022976e-02\n",
      "  -1.39414668e-02  6.53919131e-02 -2.64272932e-02  2.06392710e-04\n",
      "  -1.36643769e-02 -3.62810418e-02 -1.95043366e-02 -2.89738625e-02\n",
      "   3.94270308e-02 -8.84090886e-02  2.62429169e-03  1.36714093e-02\n",
      "   4.83063832e-02 -3.11565585e-02 -1.17329143e-01 -5.11690117e-02\n",
      "  -8.85287896e-02 -2.18963362e-02  1.42986784e-02  4.44168001e-02\n",
      "  -1.34815164e-02  7.43392482e-02  2.66382135e-02 -1.98762417e-02\n",
      "   1.79191120e-02 -1.06052961e-02 -9.04263332e-02  2.13269349e-02\n",
      "   1.41204908e-01 -6.47175964e-03 -1.40384189e-03 -1.53610259e-02\n",
      "  -8.73571187e-02  7.22173899e-02  2.01402549e-02  4.25587520e-02\n",
      "  -3.49014625e-02  3.19558487e-04 -8.02970976e-02 -3.27472650e-02\n",
      "   2.85268296e-02 -5.13658933e-02  1.09389171e-01  8.19328651e-02\n",
      "  -9.84039903e-02 -9.34095308e-02 -1.51292449e-02  4.51248810e-02\n",
      "   4.94172014e-02 -2.51867902e-02  1.57077387e-02 -1.29290745e-01\n",
      "   5.31895459e-03  4.02341736e-03 -2.34572012e-02 -6.72983378e-02\n",
      "   2.92281453e-02 -2.60845069e-02  1.30625209e-02 -3.11663207e-02\n",
      "  -4.82714064e-02 -5.58860041e-02 -3.87505963e-02  1.20010830e-01\n",
      "  -1.03924433e-02  4.89704423e-02  5.53537346e-02  4.49358821e-02\n",
      "  -4.00973111e-03 -1.02959745e-01 -2.92968042e-02 -5.83401695e-02\n",
      "   2.70472560e-02 -2.20169704e-02 -7.22241625e-02 -4.13869657e-02\n",
      "  -1.93298254e-02  2.73331674e-03  2.76948995e-04 -9.67587903e-02\n",
      "  -1.00574732e-01 -1.41922720e-02 -8.07891563e-02  4.53925543e-02\n",
      "   2.45040953e-02  5.97613566e-02 -7.38185421e-02  1.19844116e-02\n",
      "  -6.63403273e-02 -7.69045055e-02  3.85156795e-02 -5.59361962e-33\n",
      "   2.80012973e-02 -5.60784303e-02 -4.86601479e-02  2.15569958e-02\n",
      "   6.01980612e-02 -4.81402725e-02 -3.50247025e-02  1.93313565e-02\n",
      "  -1.75152346e-02 -3.89210545e-02 -3.81067139e-03 -1.70287658e-02\n",
      "   2.82100160e-02  1.28289973e-02  4.71601337e-02  6.21029325e-02\n",
      "  -6.43588901e-02  1.29285678e-01 -1.31231211e-02  5.23069687e-02\n",
      "  -3.73681076e-02  2.89094336e-02 -1.68981105e-02 -2.37329919e-02\n",
      "  -3.33491974e-02 -5.16762845e-02  1.55357067e-02  2.08802745e-02\n",
      "  -1.25371432e-02  4.59578969e-02  3.72720882e-02  2.80567184e-02\n",
      "  -5.90006076e-02 -1.16988709e-02  4.92181629e-02  4.70328443e-02\n",
      "   7.35488012e-02 -3.70529555e-02  3.98458168e-03  1.06412480e-02\n",
      "  -1.61551172e-04 -5.27165681e-02  2.75927596e-02 -3.92921865e-02\n",
      "   8.44717845e-02  4.86860350e-02 -4.85870894e-03  1.79948509e-02\n",
      "  -4.28569652e-02  1.23375421e-02  6.39958726e-03  4.04822603e-02\n",
      "   1.48887737e-02 -1.53941428e-02  7.62947649e-02  2.37043686e-02\n",
      "   4.45237532e-02  5.08194752e-02 -2.31251167e-03 -1.88737363e-02\n",
      "  -1.23334797e-02  4.66002263e-02 -5.63437864e-02  6.29927143e-02\n",
      "  -3.15535329e-02  3.24912779e-02  2.34673694e-02 -6.55437559e-02\n",
      "   2.01710071e-02  2.57082321e-02 -1.23868193e-02 -8.36498570e-03\n",
      "  -6.64377213e-02  9.43073854e-02 -3.57092842e-02 -3.42482738e-02\n",
      "  -6.66348729e-03 -8.01520888e-03 -3.09711806e-02  4.33012284e-02\n",
      "  -8.21397267e-03 -1.50795013e-01  3.07692252e-02  4.00719196e-02\n",
      "  -3.79293300e-02  1.93211716e-03  4.00530249e-02 -8.77074450e-02\n",
      "  -3.68492305e-02  8.57957359e-03 -3.19251306e-02 -1.25258518e-02\n",
      "   7.35539198e-02  1.34737790e-03  2.05918849e-02  2.71098072e-33\n",
      "  -5.18577211e-02  5.78360781e-02 -9.18985456e-02  3.94421555e-02\n",
      "   1.05576582e-01 -1.96912587e-02  6.18402883e-02 -7.63464421e-02\n",
      "   2.40880568e-02  9.40049738e-02 -1.16535500e-01  3.71198878e-02\n",
      "   5.22425398e-02 -3.95855214e-03  5.72214946e-02  5.32861799e-03\n",
      "   1.24016851e-01  1.39022768e-02 -1.10249519e-02  3.56053077e-02\n",
      "  -3.30754817e-02  8.16573873e-02 -1.52003784e-02  6.05585352e-02\n",
      "  -6.01397939e-02  3.26102823e-02 -3.48296277e-02 -1.69882178e-02\n",
      "  -9.74908099e-02 -2.71483865e-02  1.74704241e-03 -7.68982768e-02\n",
      "  -4.31857891e-02 -1.89985037e-02 -2.91661285e-02  5.77487983e-02\n",
      "   2.41821464e-02 -1.16901342e-02 -6.21435083e-02  2.84352433e-02\n",
      "  -2.37464468e-04 -2.51783431e-02  4.39632684e-03  8.12840238e-02\n",
      "   3.64184491e-02 -6.04006425e-02 -3.65517475e-02 -7.93747827e-02\n",
      "  -5.08530578e-03  6.69699460e-02 -1.17784359e-01  3.23743969e-02\n",
      "  -4.71252315e-02 -1.34460125e-02 -9.48445499e-02  8.24944768e-03\n",
      "  -1.06748752e-02 -6.81882277e-02  1.11818907e-03  2.48019919e-02\n",
      "  -6.35889471e-02  2.84492895e-02 -2.61303391e-02  8.58111233e-02\n",
      "   1.14682280e-01 -5.35345040e-02 -5.63587993e-02  4.26008329e-02\n",
      "   1.09454244e-02  2.09579039e-02  1.00131243e-01  3.26051749e-02\n",
      "  -1.84208795e-01 -3.93208824e-02 -6.91454858e-02 -6.38105944e-02\n",
      "  -6.56386465e-02 -6.41253777e-03 -4.79612239e-02 -7.68133402e-02\n",
      "   2.95383744e-02 -2.29948740e-02  4.17037010e-02 -2.50047650e-02\n",
      "  -4.54508513e-03 -4.17137183e-02 -1.32289026e-02 -6.38357848e-02\n",
      "  -2.46469979e-03 -1.37337679e-02  1.68977380e-02 -6.30397648e-02\n",
      "   8.98881406e-02  4.18170393e-02 -1.85688008e-02 -1.80442150e-08\n",
      "  -1.67998299e-02 -3.21577936e-02  6.30383715e-02 -4.13092375e-02\n",
      "   4.44819033e-02  2.02471204e-03  6.29592612e-02 -5.17374184e-03\n",
      "  -1.00444164e-02 -3.05640362e-02  3.52672786e-02  5.58581129e-02\n",
      "  -4.67124805e-02  3.45103629e-02  3.29578146e-02  4.30114232e-02\n",
      "   2.94361617e-02 -3.03164199e-02 -1.71108022e-02  7.37485588e-02\n",
      "  -5.47909550e-02  2.77515911e-02  6.20164676e-03  1.58800967e-02\n",
      "   3.42978127e-02 -5.15753822e-03  2.35079601e-02  7.53135458e-02\n",
      "   1.92843657e-02  3.36197056e-02  5.09103499e-02  1.52497083e-01\n",
      "   1.64207220e-02  2.70529017e-02  3.75162177e-02  2.18553487e-02\n",
      "   5.66333607e-02 -3.95747200e-02  7.12313801e-02 -5.41376695e-02\n",
      "   1.03772036e-03  2.11852789e-02 -3.56308967e-02  1.09017044e-01\n",
      "   2.76524969e-03  3.13997120e-02  1.38420088e-03 -3.45737562e-02\n",
      "  -4.59277928e-02  2.88082678e-02  7.16905482e-03  4.84684482e-02\n",
      "   2.61017904e-02 -9.44073219e-03  2.82169990e-02  3.48723531e-02\n",
      "   3.69098261e-02 -8.58955365e-03 -3.53206210e-02 -2.47856621e-02\n",
      "  -1.91921480e-02  3.80707644e-02  5.99653497e-02 -4.22287472e-02]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flan-T5-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors:   7%|▋         | 220M/3.13G [11:27<2:31:34, 320kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading model.safetensors:  48%|████▊     | 1.51G/3.13G [30:02<32:46, 825kB/s]  "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dp\n",
    "from dp.utils.io import read_config, save_config\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths {'checkpoint_dir': 'checkpoints', 'data_dir': 'datasets'}\n",
      "preprocessing {'languages': ['de', 'en_us', 'bn'], 'text_symbols': 'অআইঈউঊঋঌএঐওঔকখগঘঙচছজঝঞটঠডঢণতথদধনপফবভমযরলশষসহড়ঢ়য়ৎংঃঁািীুূৃেৈোৌ্০১২৩৪৫৬৭৮৯', 'phoneme_symbols': ['a', 'b', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'ç', 'ð', 'ø', 'ŋ', 'œ', 'ɐ', 'ɑ', 'ɔ', 'ə', 'ɛ', 'ɝ', 'ɹ', 'ɡ', 'ɪ', 'ʁ', 'ʃ', 'ʊ', 'ʌ', 'ʏ', 'ʒ', 'ʔ', 'ˈ', 'ˌ', 'ː', '̃', '̍', '̥', '̩', '̯', '͡', 'θ', 'ɽ', 'ɾ'], 'char_repeats': 3, 'lowercase': True, 'n_val': 5000}\n",
      "model {'type': 'transformer', 'd_model': 512, 'd_fft': 1024, 'layers': 6, 'dropout': 0.1, 'heads': 4}\n",
      "training {'learning_rate': 0.0001, 'warmup_steps': 100, 'scheduler_plateau_factor': 0.5, 'scheduler_plateau_patience': 10, 'batch_size': 32, 'batch_size_val': 32, 'epochs': 10, 'generate_steps': 500, 'validate_steps': 500, 'checkpoint_steps': 100000, 'n_generate_samples': 10, 'store_phoneme_dict_in_model': True, 'ddp_backend': 'nccl', 'ddp_host': 'localhost', 'ddp_post': '12355'}\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.dirname(dp.__file__) + '/configs/forward_config.yaml'\n",
    "config = read_config(config_file)\n",
    "config['training']['epochs'] = 10\n",
    "config['training']['warmup_steps'] = 100\n",
    "config['training']['generate_steps'] = 500\n",
    "config['training']['validate_steps'] = 500\n",
    "save_config(config, 'Configs/Deep_Phonemizer/config.yaml')\n",
    "\n",
    "for key, value in config.items():\n",
    "  print(f'{key} {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bangla_word</th>\n",
       "      <th>ipa_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>এরপরও</td>\n",
       "      <td>eɾpɔɾo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>তারা</td>\n",
       "      <td>t̪ɐɾɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>বকেয়া</td>\n",
       "      <td>bɔkeʲɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>পরিশোধ</td>\n",
       "      <td>poɾɪʃod̪ʱ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>করেনি</td>\n",
       "      <td>kɔɾenɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236558</th>\n",
       "      <td>বিবরণীতে</td>\n",
       "      <td>bɪbɔɾonɪt̪e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236559</th>\n",
       "      <td>এ</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236560</th>\n",
       "      <td>কথা</td>\n",
       "      <td>kɔt̪ʰɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236561</th>\n",
       "      <td>জানানো</td>\n",
       "      <td>ɟɐnɐno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236562</th>\n",
       "      <td>হয়েছে</td>\n",
       "      <td>hoʲecʰe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bangla_word     ipa_word\n",
       "0            এরপরও       eɾpɔɾo\n",
       "1             তারা        t̪ɐɾɐ\n",
       "2            বকেয়া       bɔkeʲɐ\n",
       "3           পরিশোধ    poɾɪʃod̪ʱ\n",
       "4            করেনি       kɔɾenɪ\n",
       "...            ...          ...\n",
       "236558    বিবরণীতে  bɪbɔɾonɪt̪e\n",
       "236559           এ            e\n",
       "236560         কথা       kɔt̪ʰɐ\n",
       "236561      জানানো       ɟɐnɐno\n",
       "236562       হয়েছে      hoʲecʰe\n",
       "\n",
       "[236563 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_parquet(\"Datasets/bangla_word_and_ipa.pq\", engine='fastparquet')\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_formatter(dataset):\n",
    "  # Make a list of tupple in this format ('bn', bengali word, ipa word)\n",
    "    formatted_dataset = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        formatted_dataset.append(('bn', row['bangla_word'], row['ipa_word']))\n",
    "    \n",
    "    return formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data = dataset_formatter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236563"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bn', 'জানালা', 'ɟɐnɐlɐ'),\n",
       " ('bn', 'ভাঙা', 'bʱɐŋɐ'),\n",
       " ('bn', 'ও', 'o'),\n",
       " ('bn', 'গ্রিল', 'gɾɪl'),\n",
       " ('bn', 'খোলা', 'kʰolɐ'),\n",
       " ('bn', 'অবস্থায়', 'ɔbost̪ʰɐe̯'),\n",
       " ('bn', 'পড়ে', 'pɔɽe'),\n",
       " ('bn', 'থাকতে', 't̪ʰɐkt̪e'),\n",
       " ('bn', 'দেখেন', 'd̪ɛkʰen'),\n",
       " ('bn', 'আদালত', 'ɐd̪ɐlɔt̪')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_data = formatted_train_data[:100]\n",
    "experiment_val_data = formatted_train_data[100:110]\n",
    "experiment_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp.preprocess import preprocess\n",
    "from dp.train import train\n",
    "from dp.phonemizer import Phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 99983.41it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess(\n",
    "    config_file='Configs/Deep_Phonemizer/config.yaml', \n",
    "    train_data=experiment_data, \n",
    "    val_data=experiment_val_data,\n",
    "    deduplicate_train_data=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SWE Class\\Github Desktop\\NLP-Learning\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Rank: 2 | Epoch: 1 | Step 1 | Loss: inf:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rank: 2 | Epoch: 1 | Step 3 | Loss: 8.419: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n",
      "Rank: 2 | Epoch: 2 | Step 6 | Loss: 8.177: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n",
      "Rank: 2 | Epoch: 3 | Step 9 | Loss: 7.804: 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]\n",
      "Rank: 2 | Epoch: 4 | Step 12 | Loss: 7.277: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]\n",
      "Rank: 2 | Epoch: 5 | Step 15 | Loss: 6.615: 100%|██████████| 3/3 [00:01<00:00,  2.50it/s]\n",
      "Rank: 2 | Epoch: 6 | Step 18 | Loss: 5.762: 100%|██████████| 3/3 [00:01<00:00,  2.65it/s]\n",
      "Rank: 2 | Epoch: 7 | Step 21 | Loss: 4.860: 100%|██████████| 3/3 [00:01<00:00,  2.53it/s]\n",
      "Rank: 2 | Epoch: 8 | Step 24 | Loss: 4.510: 100%|██████████| 3/3 [00:01<00:00,  2.57it/s]\n",
      "Rank: 2 | Epoch: 9 | Step 27 | Loss: 4.268: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]\n",
      "Rank: 2 | Epoch: 10 | Step 30 | Loss: 4.030: 100%|██████████| 3/3 [00:01<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "train(config_file='Configs/Deep_Phonemizer/config.yaml', rank=2, num_gpus=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Prediction.__init__() missing 5 required positional arguments: 'word', 'phonemes', 'phoneme_tokens', 'confidence', and 'token_probs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m dp\u001b[39m.\u001b[39;49mPrediction()\n\u001b[0;32m      2\u001b[0m x\u001b[39m.\u001b[39mphonemes(\u001b[39m'\u001b[39m\u001b[39mআমি বাংলায় গান গাই।\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Prediction.__init__() missing 5 required positional arguments: 'word', 'phonemes', 'phoneme_tokens', 'confidence', and 'token_probs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Ti Laptop GPU'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
